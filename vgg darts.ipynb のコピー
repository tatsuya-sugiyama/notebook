{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vgg darts.ipynb","provenance":[],"collapsed_sections":["LWsydO_m0MtN","fM8zsEyXcWuk","DPWZJIgIcfAg","SUQfCKp2cnFq","OUQoaMlybaLE"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"eEoEfZteii7G","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import time\n","import glob\n","import json\n","import numpy as np\n","import logging\n","import argparse\n","\n","import matplotlib.pyplot as plt\n","import datetime\n","import pytz\n","\n","import torch #基本モジュール\n","from torch.autograd import Variable #自動微分用\n","import torch.nn as nn #ネットワーク構築用\n","import torch.optim as optim #最適化関数\n","import torch.nn.functional as F #ネットワーク用の様々な関数\n","import torch.utils.data #データセット読み込み関連\n","import torchvision #画像関連\n","from torchvision import datasets, models, transforms #画像用データセット諸々\n","import torch.backends.cudnn as cudnn\n","\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfnROzhgDEGp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1600165291299,"user_tz":-540,"elapsed":1418,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}},"outputId":"a0269914-b1c1-46ef-b1e4-d818cc7cce0d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LWsydO_m0MtN","colab_type":"text"},"source":["# utils"]},{"cell_type":"markdown","metadata":{"id":"fM8zsEyXcWuk","colab_type":"text"},"source":["## other"]},{"cell_type":"code","metadata":{"id":"ZCJioEPw2esA","colab_type":"code","colab":{}},"source":["def argspace(**kwds):\n","  def deco(f):\n","    def inner(**ikwds):\n","      kwds.update(ikwds)\n","      return f(argparse.Namespace(**kwds))\n","    return inner\n","  return deco"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ml84YYEzZ_4","colab_type":"code","colab":{}},"source":["def set_seed(seed):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vPVS7mOfYboW","colab_type":"code","colab":{}},"source":["class Singleton(object):\n","  def __new__(cls, *args, **kargs):\n","    if not hasattr(cls, \"_instance\"):\n","      cls._instance = super(Singleton, cls).__new__(cls)\n","    return cls._instance"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NiwPvH9hBAqs","colab_type":"code","colab":{}},"source":["class Experiment(Singleton):\n","  def __init__(self):\n","    if not hasattr(self, 'func'):\n","      self.func = {}\n","  \n","  def _store(self, key, f):\n","    self.func.setdefault(key, {})\n","    self.func[key].update({f.__name__:(0, f)})\n","\n","  def __call__(self, key):\n","    def f(*args, **kwds):\n","      return [g(*args, **kwds) for _, g in self.func[key].values()]\n","    return f\n","\n","  def event(*key):\n","    def d(f):\n","      for k in key:\n","        Experiment()._store(k, f)\n","      def inner(*args, **kwds):\n","        return f(*args, **kwds)\n","      return inner\n","    return d\n","  \n","  def reset():\n","    Experiment().func = {}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DPWZJIgIcfAg","colab_type":"text"},"source":["## metrics"]},{"cell_type":"code","metadata":{"id":"CJ28A29Kjm_4","colab_type":"code","colab":{}},"source":["def accuracy(output, target, topk=(1,)):\n","  maxk = max(topk)\n","  batch_size = target.size(0)\n","\n","  _, pred = output.topk(maxk, 1, True, True)\n","  pred = pred.t()\n","  correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","  res = []\n","  for k in topk:\n","    correct_k = correct[:k].view(-1).float().sum(0)\n","    res.append(correct_k.mul_(100.0/batch_size))\n","  return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZUgjfdokzq8","colab_type":"code","colab":{}},"source":["class AvgrageMeter(object):\n","\n","  def __init__(self):\n","    self.reset()\n","\n","  def reset(self):\n","    self.avg = 0\n","    self.sum = 0\n","    self.cnt = 0\n","\n","  def update(self, val, n=1):\n","    self.sum += val * n\n","    self.cnt += n\n","    self.avg = self.sum / self.cnt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5HIFrNph_P8t","colab_type":"code","colab":{}},"source":["class Metrics():\n","  def __init__(self, model, dataloader):\n","    self._run(model, dataloader)\n","    self.epsilon = 1e-7\n","  \n","  @torch.no_grad()\n","  def _run(self, model, dataloader):\n","    data, target = next(iter(dataloader))\n","    device =  next(model.parameters()).device\n","    print(device)\n","    num = target.max().long() + 1\n","    cm = torch.zeros(num, num).to(device)\n","\n","    for i, (data, target) in enumerate(dataloader):\n","      data = data.to(device)\n","      target = target.to(device)\n","      outputs = model(data)\n","      _, preds = torch.max(outputs, 1)\n","      for t, p in zip(target.view(-1), preds.view(-1)):\n","        cm[t.long(), p.long()] += 1\n","\n","    self.matrix = cm\n","    self.dim = num\n","    self.sum0 = self.matrix.sum(0)\n","    self.sum1 = self.matrix.sum(1)\n","    self.sum = self.matrix.sum()\n","\n","  def confusion_matrix(self):\n","    return self.matrix\n","\n","  def TP(self, index):\n","    return self.matrix[index][index]\n","\n","  def FN(self, index):\n","    return self.sum1[index] - self.TP(index)\n","\n","  def FP(self, index):\n","    return self.sum0[index] - self.TP(index)\n","\n","  def TN(self, index):\n","    return self.sum - self.TP(index) - self.FN(index) - self.FP(index)\n","\n","  def _sum(self, F):\n","    return sum(F(i) for i in range(self.dim))\n","    \n","  def _micro(self, F, G):\n","    return self._sum(F) / (self._sum(F) + self._sum(G) + self.epsilon)\n","\n","  def _macro(self, F, G):\n","    return sum(F(i) / (F(i) + G(i) + self.epsilon) for i in range(self.dim)) / self.dim\n","\n","  def _switch(self, F, G, micro):\n","    return (self._micro(F, G) if micro else self._macro(F, G))\n","\n","  def accuracy(self, micro=True):\n","    return (self._sum(self.TP) / self.sum if micro else \n","            (sum(self.TP(i) / self.sum1 for i in range(self.dim)) / self.dim).mean())\n","\n","  def precision(self, micro=True):\n","    return self._switch(self.TP, self.FP, micro)\n","\n","  def recall(self, micro=True):\n","    return self._switch(self.TP, self.FN, micro)\n","\n","  def specificity(self, micro=True):\n","    return self._switch(self.TN, self.FP, micro)\n","\n","  def f_measure(self, micro=True):\n","    p, r = self.precision(micro), self.recall(micro)\n","    return 2 * p * r / (p + r + self.epsilon)\n","\n","  def print(self):\n","    print(self.confusion_matrix())\n","    print(\"accuracy \", self.accuracy(), self.accuracy(micro=False))\n","    print(\"precision \", self.precision(), self.precision(micro=False))\n","    print(\"recall \", self.recall(), self.recall(micro=False))\n","    print(\"specificity \", self.specificity(), self.specificity(micro=False))\n","    print(\"f_measure \", self.f_measure(), self.f_measure(micro=False))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SUQfCKp2cnFq","colab_type":"text"},"source":["## save"]},{"cell_type":"code","metadata":{"id":"zjbwvKN0qRtM","colab_type":"code","colab":{}},"source":["def path_with_time(path : str) -> str:\n","  dt_now = datetime.datetime.now(pytz.timezone('Asia/Tokyo'))\n","  return '{}-{}'.format(path, dt_now.strftime('%Y-%m-%d_%H-%M-%S'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lbL3qJOIomWe","colab_type":"code","colab":{}},"source":["def create_exp_dir(path, scripts_to_save=None):\n","  if not os.path.exists(path):\n","    os.mkdir(path)\n","  print('Experiment dir : {}'.format(path))\n","\n","  if scripts_to_save is not None:\n","    os.mkdir(os.path.join(path, 'scripts'))\n","    for script in scripts_to_save:\n","      dst_file = os.path.join(path, 'scripts', os.path.basename(script))\n","      shutil.copyfile(script, dst_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1UaF37zpTFY","colab_type":"code","colab":{}},"source":["def init_logging(save_path):\n","  class Formatter(logging.Formatter):\n","      \"\"\"override logging.Formatter to use an aware datetime object\"\"\"\n","      def converter(self, timestamp):\n","          dt = datetime.datetime.fromtimestamp(timestamp)\n","          tzinfo = pytz.timezone('Asia/Tokyo')\n","          return tzinfo.localize(dt)\n","          \n","      def formatTime(self, record, datefmt=None):\n","          dt = self.converter(record.created)\n","          if datefmt:\n","              s = dt.strftime(datefmt)\n","          else:\n","              try:\n","                  s = dt.isoformat(timespec='milliseconds')\n","              except TypeError:\n","                  s = dt.isoformat()\n","          return s\n","\n","  log_format = '%(asctime)s %(message)s'\n","  logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n","      format=log_format, datefmt='%m/%d %I:%M:%S %p')\n","  fh = logging.FileHandler(os.path.join(save_path, 'log.txt'))\n","  fh.setFormatter(Formatter(log_format))\n","  logging.getLogger().addHandler(fh)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bVnLFIMristi","colab_type":"code","colab":{}},"source":["def save_dir(dir : str, drivepath = './drive/My Drive/ml'):\n","  # TODO : init for mount drive\n","  \n","  if not dir: return\n","\n","  import subprocess\n","  res = subprocess.run([\"cp\", \"-r\", \"./\" + dir, drivepath], stdout=subprocess.PIPE)\n","  sys.stdout.write(res.stdout)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdtpwLbLudLR","colab_type":"code","colab":{}},"source":["class Store():\n","  def __init__(self, dir=\"result\", name=\"log\", fig=[]):\n","    self.dict = {}\n","    self.dir = dir\n","    self.name = name\n","    self.fig = fig\n","  \n","  def add(self, name, value):\n","    if not name in self.dict:\n","      self.dict[name] = []\n","    self.dict[name].append(value)\n","  \n","  def update(self, store : 'Store'):\n","    self.dict.update(store.dict)\n","\n","  def save(self):\n","    self.save_log()\n","    for metrix, x, y in self.fig:\n","      self.save_fig(metrix, x, y)\n","\n","  def save_log(self, name=None):\n","    name = name if name else self.name\n","    path = os.path.join(self.dir, name + \".txt\")\n","    with open(path, mode='w') as f:\n","      f.write(\"%s\" % self.dict)\n","\n","  def save_fig(self, metrix, xlabel, ylabel, show=True):\n","    fig = plt.figure()\n","\n","    if type(metrix) is str:\n","      times = len(self.dict[metrix])\n","      plt.plot(np.arange(times), self.dict[metrix])\n","    else :\n","      times = len(self.dict[metrix[0]])\n","      for m in metrix:\n","        plt.plot(np.arange(times), self.dict[m], label=m)\n","      metrix = \"_\".join(metrix)\n","    \n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    plt.legend()\n","    if show: plt.show()\n","    fig.savefig(os.path.join(self.dir, \"%s_%d.png\" % (metrix, times)))\n","\n","  def __repr__(self):\n","    return \"store in %s\" % self.dict"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OUQoaMlybaLE","colab_type":"text"},"source":["# dataset"]},{"cell_type":"code","metadata":{"id":"aMQcdozPm31Z","colab_type":"code","colab":{}},"source":["def load_dataset(train=2000, test=500, valid=0):\n","  #画像の変形処理\n","  transform = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","  ])\n","\n","  transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","  ])\n","\n","  dataset = torchvision.datasets.CIFAR10\n","  kwargs = {\"root\" : \"./data\", \"download\" : True}\n","\n","  #CIFAR-10のtrain, testsetのロード\n","  trainset = dataset(train=True, transform=transform, **kwargs)\n","  testset = dataset(train=False, transform=transform_test, **kwargs)\n","  \n","  trainset, validset, _ = torch.utils.data.random_split(trainset, [train, valid, 50000-train-valid])\n","  testset, _ = torch.utils.data.random_split(testset, [test, 10000-test])\n","  return argparse.Namespace(train=trainset, test=testset, valid=validset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNDJPZLxAY0B","colab_type":"code","colab":{}},"source":["def load_dataloader(args):\n","  kwargs = {'num_workers': 1, 'pin_memory': True} if args.use_cuda else {}\n","  args.valid_size = args.valid_size if args.valid_size else 0\n","  sets = load_dataset(train=args.train_size, test=args.test_size, valid=args.valid_size)\n","  trainloader = torch.utils.data.DataLoader(sets.train, batch_size=args.batch_size, shuffle=True, **kwargs)\n","  validloader = torch.utils.data.DataLoader(sets.valid, batch_size=args.batch_size, shuffle=True, **kwargs)\n","  testloader = torch.utils.data.DataLoader(sets.test, batch_size=args.batch_size, shuffle=False, **kwargs)\n","  return argparse.Namespace(train=trainloader, test=testloader, valid=validloader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nmXw5AGs0TLl","colab_type":"text"},"source":["# model"]},{"cell_type":"code","metadata":{"id":"Hdd_Mu8gisSi","colab_type":"code","colab":{}},"source":["cfg = {\n","    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}\n","\n","class VGG(nn.Module):\n","    def __init__(self, vgg_name):\n","        super(VGG, self).__init__()\n","        self.features = self._make_layers(cfg[vgg_name])\n","        self.classifier = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        return out\n","\n","    def _make_layers(self, cfg):\n","        layers = []\n","        in_channels = 3\n","        for x in cfg:\n","            if x == 'M':\n","                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","            else:\n","                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n","                           nn.BatchNorm2d(x),\n","                           nn.ReLU(inplace=True)]\n","                in_channels = x\n","        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n","        return nn.Sequential(*layers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_uyawqz6UEv","colab_type":"code","colab":{}},"source":["class Shortcut(nn.Module):\n","  def __init__(self, in_channel, out_channel, stride):\n","    super(Shortcut, self).__init__()\n","    self.f = self._shortcut(in_channel, out_channel, stride)\n","\n","  def forward(self, x):\n","    return self.f(x)\n","\n","  def _shortcut(self, channel_in, channel_out, stride):\n","    if channel_in != channel_out or stride > 1:\n","      return nn.Conv2d(channel_in, channel_out, \n","                       kernel_size=1, stride=stride, padding=0)\n","    else:\n","      return lambda x: x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHHLMEl5lNZt","colab_type":"code","colab":{}},"source":["class Block(nn.Module):\n","  def __init__(self, index, in_channel, out_channel, stride, shortcuts):\n","    super(Block, self).__init__()\n","    self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1)\n","    self.bn = nn.BatchNorm2d(out_channel)\n","    self.relu = nn.ReLU(inplace=True)\n","    self.stride = stride\n","    if stride: self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.shortcuts = self._make_shortcuts(shortcuts)\n","    self.enable = len(self.shortcuts) > 0\n","    self.index = index\n","    self.connection = [i for i, _, _, _ in shortcuts]\n","\n","  def _make_shortcuts(self, shortcuts):\n","    layers = nn.ModuleList()\n","    for (index, i, o, s) in shortcuts:\n","      layers += [Shortcut(i, o, s)]\n","    return layers\n","\n","  def forward(self, x, xs, alpha):\n","    output = self.bn(self.conv(x))\n","\n","    if self.enable:\n","      # shortcut\n","      cut = sum(alpha[i] * F(xs[i]) for i, F in enumerate(self.shortcuts))\n","      output = output + cut\n","    \n","    output = self.relu(output)\n","\n","    if self.stride:\n","      output = self.pool(output)\n","\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hQ9-qdW5ko9R","colab_type":"code","colab":{}},"source":["class Network(nn.Module):\n","  def __init__(self, gene):\n","    super(Network, self).__init__()\n","    self.gene = gene\n","    self.blocks = self._make_blocks(gene)\n","    self.pool = nn.AvgPool2d(kernel_size=1, stride=1)\n","    self.classifier = nn.Linear(512, 10)\n","\n","  def _decode_gene(self, gene):\n","    ch, st = [], []\n","    for g in gene:\n","      if g == 'M':\n","        st[-1] *= 2\n","      else :\n","        ch += [g]\n","        st += [1]\n","    return ch, st\n","\n","  def _make_blocks(self, gene):\n","    channel, stride = self._decode_gene(gene)\n","    s_stride = self.__pi(stride)\n","    blocks = nn.ModuleList()\n","    in_channel = 3\n","    for i, (c, s) in enumerate(zip(channel, stride)):\n","      setting = []\n","      for j in range(i-1):\n","        setting += [(j, channel[j], c, int(s_stride[i-1] / s_stride[j]))]\n","      blocks += [Block(i, in_channel, c, s>1, setting)]\n","      in_channel = c\n","    return blocks\n","\n","  def _init_alpha(self, blocks, device, delta=1e-3):\n","    alpha = []\n","\n","    for block in blocks:\n","      a = delta * torch.randn(len(block.connection))\n","      alpha += [torch.tensor(a, requires_grad=True, device=device)]\n","\n","    return alpha\n","  \n","  def init_alpha(self, device):\n","    self.alphas = self._init_alpha(self.blocks, device)\n","    return self\n","\n","  def __pi(self, array):\n","    r = []\n","    s = 1\n","    for q in array:\n","      s *= q\n","      r += [s]\n","    return r\n","\n","  def forward(self, x):\n","    state = []\n","\n","    for idx, block in enumerate(self.blocks):\n","      xs = [state[i] for i in block.connection]\n","      x = block(x, xs, F.softmax(self.alphas[idx], dim=0))\n","      state += [x]\n","\n","    out = self.pool(x)\n","    out = out.view(out.size(0), -1)\n","    out = self.classifier(out)\n","    return out\n","\n","  @torch.no_grad()\n","  def alpha_tensor(self, softmax=True):\n","    alpha = torch.zeros(len(self.alphas), max([len(a) for a in self.alphas]))\n","    for i, a in enumerate(self.alphas):\n","      alpha[i, :len(a)] = F.softmax(a, dim=0) if softmax else a\n","    return alpha"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F4Q7p8JyXk9f","colab_type":"code","colab":{}},"source":["class Architect():\n","  def __init__(self, valid_loader, model, criterion, lr, device):\n","    self.valid_loader = valid_loader\n","    self.model = model\n","    self.criterion = criterion\n","    self.optimizer = optim.Adam(model.alphas, lr=lr, betas=(0.5, 0.999), weight_decay=1e-3)\n","    self.device = device\n","\n","  def step(self):\n","    data_v, target_v = next(iter(self.valid_loader))\n","    data_v, target_v = data_v.to(self.device), target_v.to(self.device)\n","\n","    self.optimizer.zero_grad()\n","    output = self.model(data_v)\n","    loss = self.criterion(output, target_v)\n","    loss.backward()\n","    self.optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"26E8hA820WWG","colab_type":"text"},"source":["# learning"]},{"cell_type":"code","metadata":{"id":"xKYJMQebTseQ","colab_type":"code","colab":{}},"source":["@Experiment.event('setup')\n","def setup(args):\n","  args.save = path_with_time(args.save)\n","  create_exp_dir(args.save, scripts_to_save=glob.glob('*.py'))\n","  init_logging(args.save)\n","  logging.info('kwargs %s' % args)\n","  \n","  args.start_epoch = 0\n","\n","  # cuda init\n","  args.use_cuda = torch.cuda.is_available()\n","  args.device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n","\n","  # log init\n","  fig = [([\"train_acc\", \"test_acc\"], \"epochs\", \"accuracy[%]\"),\n","         ([\"train_loss\", \"test_loss\"], \"epochs\", \"loss\")]\n","  store = Store(dir=args.save, name=\"store\", fig=fig)\n","  args.store = store\n","\n","  set_seed(args.seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sjuq4RUvWGnU","colab_type":"code","colab":{}},"source":["@Experiment.event('checkpoint', 'end')\n","def save_checkpoint(args):\n","  args.store.save()\n","  save_dir(args.save)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CNo6kmtFi1bh","colab_type":"code","colab":{}},"source":["@argspace(retain_graph=True)\n","def train(args):\n","  objs = AvgrageMeter()\n","  top1 = AvgrageMeter()\n","  top5 = AvgrageMeter()\n","  args.model.train()\n","\n","  for step, (input, target) in enumerate(args.dataset):\n","    n = input.size(0)\n","\n","    input = Variable(input, requires_grad=False).to(args.device)\n","    target = Variable(target, requires_grad=False).to(args.device)\n","\n","    args.architect.step()\n","\n","    args.optimizer.zero_grad()\n","    logits = args.model(input)\n","    loss = args.criterion(logits, target)\n","\n","    loss.backward(retain_graph=args.retain_graph)\n","    # nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n","    args.optimizer.step()\n","\n","    prec1, prec5 = accuracy(logits, target, topk=(1, 5))\n","    objs.update(loss.item(), n)\n","    top1.update(prec1.item(), n)\n","    top5.update(prec5.item(), n)\n","\n","    if step % args.report_freq == 0:\n","      logging.info('train %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n","\n","  return top1.avg, objs.avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQKeYZkwi2Dx","colab_type":"code","colab":{}},"source":["@argspace()\n","def infer(args):\n","  objs = AvgrageMeter()\n","  top1 = AvgrageMeter()\n","  top5 = AvgrageMeter()\n","  args.model.eval()\n","\n","  for step, (input, target) in enumerate(args.dataset):\n","    input = Variable(input, requires_grad=False).to(args.device)\n","    target = Variable(target, requires_grad=False).to(args.device)\n","\n","    logits = args.model(input)\n","    loss = args.criterion(logits, target)\n","\n","    prec1, prec5 = accuracy(logits, target, topk=(1, 5))\n","    n = input.size(0)\n","    objs.update(loss.item(), n)\n","    top1.update(prec1.item(), n)\n","    top5.update(prec5.item(), n)\n","\n","    if step % args.report_freq == 0:\n","      logging.info('valid %03d %e %f %f', step, objs.avg, top1.avg, top5.avg)\n","\n","  return top1.avg, objs.avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tTUPG9pfq20n","colab_type":"code","colab":{}},"source":["@argspace()\n","def main(args):\n","\n","  # init\n","  exp = Experiment()\n","  exp('setup')(args)\n","  store = args.store\n","  device = args.device\n","\n","  # model setup\n","  gene = cfg['VGG11']\n","  logging.info('gene %s', gene)\n","  model = Network(gene).to(device).init_alpha(device)\n","\n","  if device == 'cuda':\n","    model = torch.nn.DataParallel(model)\n","    cudnn.benchmark = True\n","\n","  if args.dir:\n","    state = torch.load(os.path.join(args.dir, 'checkpoint.pth'))\n","    model.load_state_dict(state['model'])\n","    model.alphas = state['alpha']\n","    args.start_epoch = state['epoch']\n","    store.update(state['store'])\n","    logging.info('Resuming from epoch %d in %s' % (args.start_epoch, args.dir))\n","\n","  loader = load_dataloader(args)\n","\n","  optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=5e-4)\n","  criterion = nn.CrossEntropyLoss()\n","  architect = Architect(loader.valid, model, criterion, args.lr_alpha, device)\n","\n","\n","  for epoch in range(args.start_epoch + 1, args.epochs + 1):\n","    logging.info('epoch %d', epoch)\n","    # print(\"grad\", model.alphas[0].requires_grad)\n","    logging.info('alpha %s', model.alpha_tensor())\n","    logging.info('alpha %s', model.alpha_tensor(softmax=False))\n","\n","    # training\n","    train_acc, train_obj = train(dataset=loader.train, model=model, \n","                                 criterion=criterion, optimizer=optimizer, \n","                                 architect=architect, \n","                                 device=device, report_freq=args.report)\n","    logging.info('train_acc %f', train_acc)\n","    store.add(\"train_loss\", train_obj)\n","    store.add(\"train_acc\", train_acc)\n","\n","    # validation\n","    valid_acc, valid_obj = infer(dataset=loader.test, model=model, \n","                                 criterion=criterion,\n","                                 device=device, report_freq=args.report)\n","    logging.info('valid_acc %f', valid_acc)\n","    store.add(\"test_loss\", valid_obj)\n","    store.add(\"test_acc\", valid_acc)\n","\n","    if epoch % args.checkpoint == 0:\n","      exp('checkpoint')(args)\n","      state = {\n","        'model': model.state_dict(),\n","        'alpha': model.alphas,\n","        'store': store,\n","        'epoch': epoch,\n","      }\n","      torch.save(state, os.path.join(args.save, 'checkpoint.pth'))\n","\n","  exp('end')(args)\n","  state = {\n","    'model': model.state_dict(),\n","    'alpha': model.alphas,\n","    'store': store,\n","    'epoch': epoch,\n","  }\n","  torch.save(state, os.path.join(args.save, 'checkpoint.pth'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nGjJsHh50xtj","colab_type":"text"},"source":["# main"]},{"cell_type":"code","metadata":{"id":"f4BFc-WUjat9","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  for i in range(1, 10):\n","    print(\"=\" * 40)\n","    print(\"learning %d\" % i)\n","    main(save=\"variance\", lr=0.01, momentum=0.9, lr_alpha=0.005, epochs=30, \n","        train_size=10000, valid_size=10000, test_size=5000, batch_size=64, \n","        seed=i, report=100, checkpoint=10, dir=\"\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EuByAf2cLRoS","colab_type":"text"},"source":["# exp"]},{"cell_type":"markdown","metadata":{"id":"s--FDQ74LxBJ","colab_type":"text"},"source":["TODO\n","- watch model size, memory\n","- early stopping"]},{"cell_type":"code","metadata":{"id":"rHZ2XSodc0JH","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}