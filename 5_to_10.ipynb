{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_to_10.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2f3d7127d56c475fbd501aa7781c009e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d854208b897146bea1e06186f290d14a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fd31ba0f2ef743c6bbae16f1a4025654","IPY_MODEL_ac6bc450842a4bf683e8ab95341b00bf"]}},"d854208b897146bea1e06186f290d14a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd31ba0f2ef743c6bbae16f1a4025654":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cc82645be89a4dc8baf5dfef92d41f3c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75316bb5417f4f65a97628194116fc45"}},"ac6bc450842a4bf683e8ab95341b00bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7b28c0b2a4934ab1873f0f395b1a5c51","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:22&lt;00:00, 32201976.89it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c63ee816e50d4ad4a5637a42dd3186d6"}},"cc82645be89a4dc8baf5dfef92d41f3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"75316bb5417f4f65a97628194116fc45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b28c0b2a4934ab1873f0f395b1a5c51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c63ee816e50d4ad4a5637a42dd3186d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"C7MTsbZo7q0H","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592441755270,"user_tz":-540,"elapsed":4223,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}}},"source":["import torch #基本モジュール\n","from torch.autograd import Variable #自動微分用\n","import torch.nn as nn #ネットワーク構築用\n","import torch.optim as optim #最適化関数\n","import torch.nn.functional as F #ネットワーク用の様々な関数\n","import torch.utils.data #データセット読み込み関連\n","import torchvision #画像関連\n","from torchvision import datasets, models, transforms #画像用データセット諸々\n","\n","import numpy as np\n","import argparse\n","import json\n","from logging.config import dictConfig\n","from logging import getLogger\n","import os\n","import time\n","from google.colab import files"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fl8b4uzs7yxo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592441755273,"user_tz":-540,"elapsed":2351,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}}},"source":["class CNN(nn.Module):\n","    def __init__(self, n_class=10):\n","        super(CNN, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.Conv2d(64, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Dropout(0.25),\n","            \n","            nn.Conv2d(64, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            nn.Conv2d(128, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Dropout(0.25),\n","            \n","            nn.Conv2d(128, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(256),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(256),\n","            nn.Conv2d(256, 512, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, padding=1),\n","            nn.ReLU(),\n","            nn.AvgPool2d(8) #???\n","        )\n","        self.pc = nn.Sequential(\n","            nn.Linear(512, 1024),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024, 1024),\n","            nn.Dropout(0.5),\n","            nn.Linear(1024, n_class),\n","            nn.Softmax()\n","        )\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        x = x.view(-1, 512)\n","        x = self.pc(x)\n","        return x"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"0gNeXy87M49K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592443285823,"user_tz":-540,"elapsed":849,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}}},"source":["class catCNN(nn.Module):\n","  def __init__(self, models, device, n_class=10):\n","    super(catCNN, self).__init__()\n","    self.models = models\n","    self.n_class = n_class\n","    self.device = device\n","\n","  def forward(self, x):\n","    batch_size = x.shape[0]\n","    output = torch.zeros(batch_size, self.n_class).to(self.device)\n","    count = torch.zeros(self.n_class).to(self.device)\n","    for idx, model in self.models:\n","      idx = torch.tensor(idx).to(self.device)\n","      # output.index_add_(1, idx, model(x) * idx.shape[0])\n","      output.index_add_(1, idx, model(x))\n","      count[idx] += 1\n","    \n","    output = output / count\n","    # output = nn.Softmax(dim=1)(output)\n","    return output"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkUWcG0A70Iu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592441760054,"user_tz":-540,"elapsed":876,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}}},"source":["def train(model, device, train_loader, optimizer, criterion, logger, class_array):\n","    model.train()\n","    class_array = torch.LongTensor(class_array).to(device)\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        reg = torch.zeros(output.shape[0], 10).to(device)\n","        # reg[class_array] = output\n","        reg.index_add_(1, class_array, output)\n","        loss = criterion(reg, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 100 == 0:\n","            logger.debug(\"[train] batch : %s/%s (%.0f%%),\\tloss : %.6f\",\n","                batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item())\n","    return (None, loss.item())"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zy3VxoCY74me","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592441760918,"user_tz":-540,"elapsed":795,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}}},"source":["def test(model, device, test_loader, criterion, logger, class_array):\n","    model.eval()\n","    test_loss = []\n","    correct = 0\n","    # result = []\n","    class_array = torch.tensor(class_array).to(device)\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(test_loader):\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss.append(criterion(output, target).item())\n","            pred = class_array[output.argmax(dim=1, keepdim=True)]\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","            # result += torch.eq(torch.max(output, 1).indices, target) # not apply\n","            \n","    test_loss = np.mean(np.array(test_loss))\n","    accuracy = 100. * correct / len(test_loader.dataset)\n","    \n","    logger.info(\"[test] ave loss : %.4f,\\taccu : %d/%d(%.0f%%)\",\n","        test_loss, correct, len(test_loader.dataset), accuracy)\n","    \n","    # return (torch.tensor(result).numpy(), (test_loss, accuracy))\n","    return (None, (test_loss, accuracy))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ft0I0uKFEvFF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592441762800,"user_tz":-540,"elapsed":1145,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}}},"source":["def main(description, option=\"\"):\n","    with open('logging.json') as f:\n","        dictConfig(json.load(f))\n","    logger = getLogger('env')\n","    logger.debug(\"<\" * 40)\n","    logger.info(\"[system] start\")\n","    logger.info(\"[meta] %s\", description)\n","    start_time = time.time()\n","\n","    def fetch_args(args=[]):\n","        parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n","        parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n","                            help='input batch size for training (default: 64)')\n","        parser.add_argument('--epochs', type=int, default=14, metavar='N',\n","                            help='number of epochs to train (default: 14)')\n","        parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n","                            help='learning rate (default: 0.001)')\n","        parser.add_argument('--b1', type=float, default=0.9, metavar='B',\n","                            help='learning rate beta (default: 0.9)')\n","        parser.add_argument('--b2', type=float, default=0.999, metavar='B',\n","                            help='learning rate beta (default: 0.999)')\n","        parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n","                            help='learning rate momentum (default: 0.9)')\n","        parser.add_argument('--dataset', default=\"cifar10\", metavar='D')\n","        parser.add_argument('--n-class', type=int, default=10, metavar='C')\n","        parser.add_argument('--n-class-offset', type=int, default=0, metavar='C')\n","        parser.add_argument('--data-size', type=int, default=25000, metavar='D')\n","        parser.add_argument('--model', default=\"cnn\", metavar='M')\n","        parser.add_argument('--optimizer', default=\"adam\", metavar='O')\n","        parser.add_argument('--criterion', default=\"cross_entropy_loss\", metavar='C')\n","        parser.add_argument('--scheduler', default=\"\", metavar='S')\n","        parser.add_argument('--t-max', type=int, default=10, metavar='T')\n","        parser.add_argument('--save-model', action='store_true', default=True,\n","                            help='For Saving the current Model')\n","        parser.add_argument('--model-name', default=\"model\", metavar='M')\n","        return parser.parse_args(args=args)\n","  \n","    args = fetch_args(option.split(\" \"))\n","    for arg in vars(args):\n","        logger.info(\"[param] %s=%s\", arg, vars(args)[arg])\n","    \n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    logger.info(\"[device] %s\", device)\n","    \n","    #画像の変形処理\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    #CIFAR-10のtrain, testsetのロード\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                            download=True, transform=transform)\n","    \n","    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","\n","    def subset_dataloader(set):\n","      return torch.utils.data.DataLoader(\n","          torch.utils.data.Subset(trainset, set), \n","          batch_size=args.batch_size, shuffle=False, **kwargs)\n","\n","    # init\n","    def make_dataset(n_class, data_size):\n","      full_labels = []\n","      full_indices = np.arange(len(trainset))\n","      for (_, target) in subset_dataloader(full_indices):\n","        full_labels += target.numpy().tolist()\n","      full_labels = np.array(full_labels)\n","\n","      indices = np.array([], dtype=np.int64)\n","      class_sample = int(data_size / len(n_class))\n","      for c in n_class:\n","        mask = full_labels == c\n","        indices = np.concatenate([indices, full_indices[mask][:class_sample]])\n","\n","      np.random.shuffle(indices)\n","      return (indices, None, full_labels)\n","\n","    N = int(args.data_size)\n","    class_array = [(i + args.n_class_offset) % 10 for i in range(args.n_class)]\n","    class_array = np.array(class_array)\n","    print(class_array)\n","    indices, _, labels = make_dataset(class_array, 2 * N)\n","    A, B = indices[:N], indices[N:]\n","    logger.debug(\"[debug] labels : %s\", labels.tolist())\n","\n","    log = {\"X_train\":[], \"X_test\":[], \"X_acc\":[]}\n","\n","\n","    def learning():\n","      # instantiate\n","      if True:\n","        model_X = CNN(n_class=args.n_class).to(device)\n","\n","        if args.optimizer == \"adam\":\n","          optimizer_X = optim.Adam(model_X.parameters(), lr=args.lr, betas=(args.b1, args.b2))\n","        if args.optimizer == \"adagrad\":\n","          optimizer_X = optim.Adagrad(model_X.parameters(), lr=args.lr)\n","        if args.optimizer == \"sdg\":\n","          optimizer_X = optim.SGD(model_X.parameters(), lr=args.lr, momentum=args.momentum)\n","        if args.optimizer == \"asdg\":\n","          optimizer_X = optim.ASGD(model_X.parameters(), lr=args.lr)\n","\n","        scheduler_X = None\n","        if args.scheduler == \"cosine_annealing\":\n","          scheduler_X = optim.lr_scheduler.CosineAnnealingLR(optimizer_X, T_max=args.t_max, eta_min=1e-6)\n","        if args.scheduler == \"step\":\n","          def func(epoch):\n","            return 0.5 ** (epoch // 50)\n","          scheduler_X = optim.lr_scheduler.LambdaLR(optimizer_X, lr_lambda = func)\n","        criterion = nn.CrossEntropyLoss()\n","\n","      # Split\n","      A_loader, B_loader = subset_dataloader(A), subset_dataloader(B)\n","      \n","      def fit_X():\n","        logger.info(\"[system] X\")\n","        for epoch in range(args.epochs):\n","          logger.debug(\"-\" * 20)\n","          logger.info(\"[system] epoch %d\", epoch)\n","\n","          (_, loss_XA) = train(model_X, device, A_loader, optimizer_X, criterion, logger, class_array)\n","          (testB, (loss_XB, acc_X)) = test(model_X, device, B_loader, criterion, logger, class_array)\n","          if scheduler_X: scheduler_X.step()\n","        \n","          log[\"X_train\"].append(loss_XA)\n","          log[\"X_test\"].append(loss_XB)\n","          log[\"X_acc\"].append(acc_X)\n","        return testB\n","\n","      # training\n","      testB = fit_X()\n","\n","      # save\n","      if args.save_model:\n","        logger.info(\"[system] saving...\")\n","        result_dir = \"result\"\n","        result_path = os.path.join(result_dir, args.model_name + \".pt\")\n","        if not os.path.exists(result_dir):\n","          os.mkdir(result_dir)\n","\n","        torch.save(model_X.state_dict(), result_path)\n","        # print(os.path.join(\"/content\", result_path))\n","        # files.download(os.path.join(\"/content\", result_path))\n","\n","\n","    learning()\n","\n","    # Statistics\n","    logger.debug(\"%s statistics %s\", \"-\" * 10, \"-\" * 10)\n","    logger.info(\"[stat] X train loss : %s\", log[\"X_train\"])\n","    logger.info(\"[stat] X test loss : %s\", log[\"X_test\"])\n","    logger.info(\"[stat] X accuracy : %s\", log[\"X_acc\"])\n","    logger.info(\"[stat] elapsed time : %s[s]\", time.time() - start_time)\n","    \n","    logger.info(\"[system] finish\")\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"CMRx-KNomQsX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592443090072,"user_tz":-540,"elapsed":891,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}}},"source":["def main(description, option=\"\"):\n","    with open('logging.json') as f:\n","        dictConfig(json.load(f))\n","    logger = getLogger('env')\n","    logger.debug(\"<\" * 40)\n","    logger.info(\"[system] start\")\n","    logger.info(\"[meta] %s\", description)\n","    start_time = time.time()\n","\n","    def fetch_args(args=[]):\n","        parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n","        parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n","                            help='input batch size for training (default: 64)')\n","        parser.add_argument('--epochs', type=int, default=14, metavar='N',\n","                            help='number of epochs to train (default: 14)')\n","        parser.add_argument('--trials', type=int, default=10, metavar='T')\n","        parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n","                            help='learning rate (default: 0.001)')\n","        parser.add_argument('--b1', type=float, default=0.9, metavar='B',\n","                            help='learning rate beta (default: 0.9)')\n","        parser.add_argument('--b2', type=float, default=0.999, metavar='B',\n","                            help='learning rate beta (default: 0.999)')\n","        parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n","                            help='learning rate momentum (default: 0.9)')\n","        parser.add_argument('--dataset', default=\"cifar10\", metavar='D')\n","        parser.add_argument('--n-class', type=int, default=10, metavar='C')\n","        parser.add_argument('--n-class-offset', type=int, default=0, metavar='C')\n","        # parser.add_argument('--n-class-marge', type=int, default=0, metavar='C')\n","        parser.add_argument('--data-size', type=int, default=25000, metavar='D')\n","        parser.add_argument('--model', default=\"cnn\", metavar='M')\n","        parser.add_argument('--optimizer', default=\"adam\", metavar='O')\n","        parser.add_argument('--criterion', default=\"cross_entropy_loss\", metavar='C')\n","        parser.add_argument('--scheduler', default=\"\", metavar='S')\n","        parser.add_argument('--t-max', type=int, default=10, metavar='T')\n","        parser.add_argument('--save-model', action='store_true', default=True,\n","                            help='For Saving the current Model')\n","        parser.add_argument('--model-name', default=\"model\", metavar='M')\n","        return parser.parse_args(args=args)\n","  \n","    args = fetch_args(option.split(\" \"))\n","    for arg in vars(args):\n","        logger.info(\"[param] %s=%s\", arg, vars(args)[arg])\n","    \n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","    logger.info(\"[device] %s\", device)\n","    \n","    #画像の変形処理\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    #CIFAR-10のtrain, testsetのロード\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                            download=True, transform=transform)\n","    \n","    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","\n","    def subset_dataloader(set):\n","      return torch.utils.data.DataLoader(\n","          torch.utils.data.Subset(trainset, set), \n","          batch_size=args.batch_size, **kwargs)\n","\n","    # init\n","    def make_dataset(n_class, data_size):\n","      full_labels = []\n","      full_indices = np.arange(len(trainset))\n","      for (_, target) in subset_dataloader(full_indices):\n","        full_labels += target.numpy().tolist()\n","\n","      pack = np.array([(i, full_labels[i]) for i in range(len(full_labels))\n","              if full_labels[i] in n_class])\n","      np.random.shuffle(pack)\n","      pack = pack[:data_size].tolist()\n","\n","      indices = [i for (i, _) in pack]\n","      labels = [label for (_, label) in pack]\n","      return (np.array(indices), np.array(labels), np.array(full_labels))\n","\n","    N = int(args.data_size)\n","    class_array = np.arange(args.n_class) + args.n_class_offset\n","    print(class_array)\n","    indices, _, labels = make_dataset(class_array, 2 * N)\n","    A, B = indices[:N], indices[N:]\n","    # A = indices\n","    logger.debug(\"[debug] labels : %s\", labels.tolist())\n","\n","    log = {\"X_train\":[], \"X_test\":[], \"X_acc\":[]}\n","\n","\n","    def learning():\n","      # instantiate\n","      if True:\n","        models = []\n","\n","        def model_init(n_class, paths):\n","          models = []\n","          for idx, path in enumerate(paths):\n","            x = CNN(n_class=n_class).to(device)\n","            x.load_state_dict(torch.load(path))\n","            x.eval()\n","            xc = [(i + n_class * idx) % args.n_class for i in range(n_class)]\n","            models.append((xc, x))\n","          return models\n","\n","        # n_class = 7\n","        # paths = [\"/content/result/model_7A_64.pt\",\n","        #          \"/content/result/model_7B_64.pt\",\n","        #          \"/content/result/model_7C_64.pt\"]\n","        # models += model_init(n_class, paths)\n","\n","        n_class = 5\n","        paths = [\"/content/result/model_5A_64.pt\",\n","                 \"/content/result/model_5B_64.pt\"]\n","        models += model_init(n_class, paths)\n","\n","        model_X = catCNN(models, device).to(device)\n","\n","        criterion = nn.CrossEntropyLoss()\n","\n","      # Split\n","      A_loader, B_loader = subset_dataloader(A), subset_dataloader(B)\n","      \n","      def fit_X():\n","        logger.info(\"[system] X\")\n","        for epoch in range(args.epochs):\n","          logger.debug(\"-\" * 20)\n","          logger.info(\"[system] epoch %d\", epoch)\n","\n","          # (_, loss_XA) = train(model_X, device, A_loader, optimizer_X, criterion, logger)\n","          (testB, (loss_XB, acc_X)) = test(model_X, device, B_loader, criterion, logger, class_array)\n","          # if scheduler_X: scheduler_X.step() # うごいてなさそう\n","        \n","          # log[\"X_train\"].append(loss_XA)\n","          log[\"X_test\"].append(loss_XB)\n","          log[\"X_acc\"].append(acc_X)\n","        return testB\n","\n","      # training\n","      testB = fit_X()\n","\n","      # save\n","      if args.save_model:\n","        logger.info(\"[system] saving...\")\n","        result_dir = \"result\"\n","        result_path = os.path.join(result_dir, args.model_name + \".pt\")\n","        if not os.path.exists(result_dir):\n","          os.mkdir(result_dir)\n","\n","        torch.save(model_X.state_dict(), result_path)\n","        # print(os.path.join(\"/content\", result_path))\n","        # files.download(os.path.join(\"/content\", result_path))\n","\n","\n","    learning()\n","\n","    # Statistics\n","    logger.debug(\"%s statistics %s\", \"-\" * 10, \"-\" * 10)\n","    logger.info(\"[stat] X train loss : %s\", log[\"X_train\"])\n","    logger.info(\"[stat] X test loss : %s\", log[\"X_test\"])\n","    logger.info(\"[stat] X accuracy : %s\", log[\"X_acc\"])\n","    logger.info(\"[stat] elapsed time : %s[s]\", time.time() - start_time)\n","    \n","    logger.info(\"[system] finish\")\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"WYpONRnfEBYm","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  option = \"--epochs 3 --batch-size 16 --optimizer sdg --data-size 100 \" + \\\n","           \"--n-class 5 --n-class-offset 5 --model-name=model_0to4\"\n","  main(\"デバッグ\", option=option)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e8--o9wvY4xh","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  # option = \"--epochs 200 --batch-size 16 --optimizer sdg --data-size 20000 \" + \\\n","  #          \"--n-class 5 --n-class-offset 0 --model-name=model_0to4\"\n","  # main(\"5 class A\", option=option)\n","\n","  # option = \"--epochs 100 --batch-size 16 --optimizer sdg --data-size 2000 \" + \\\n","  #          \"--n-class 5 --n-class-offset 5 --model-name=model_5to9\"\n","  # main(\"5 class B\", option=option)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0CFNBvzBf2o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"ok","timestamp":1592443316927,"user_tz":-540,"elapsed":25320,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}},"outputId":"eeb9e226-dc66-46be-fc51-51fc409f1674"},"source":["if __name__ == '__main__':\n","  option = \"--epochs 1 --batch-size 16 --optimizer sdg --data-size 2000 \" + \\\n","           \"--n-class 10 --n-class-offset 0 --model-name=model_10\"\n","  main(\"10 class concat\", option=option)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[system] start\n","[meta] 10 class concat\n","[param] batch_size=16\n","[param] epochs=1\n","[param] trials=10\n","[param] lr=0.001\n","[param] b1=0.9\n","[param] b2=0.999\n","[param] momentum=0.9\n","[param] dataset=cifar10\n","[param] n_class=10\n","[param] n_class_offset=0\n","[param] data_size=2000\n","[param] model=cnn\n","[param] optimizer=sdg\n","[param] criterion=cross_entropy_loss\n","[param] scheduler=\n","[param] t_max=10\n","[param] save_model=True\n","[param] model_name=model_10\n","[device] cuda\n"],"name":"stderr"},{"output_type":"stream","text":["Files already downloaded and verified\n","[0 1 2 3 4 5 6 7 8 9]\n"],"name":"stdout"},{"output_type":"stream","text":["[system] X\n","[system] epoch 0\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n","[test] ave loss : 1.6607,\taccu : 1384/2000(69%)\n","[system] saving...\n","[stat] X train loss : []\n","[stat] X test loss : [1.6606930303573608]\n","[stat] X accuracy : [69.2]\n","[stat] elapsed time : 24.473531007766724[s]\n","[system] finish\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QkICfS6IIr-q","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","           \"--lr 0.001 \" + \\\n","           \"--n-class 7 --n-class-offset 0 --model-name=model_7A_64\"\n","  main(\"7 class A\", option=option)\n","\n","  option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","           \"--lr 0.001 \" + \\\n","           \"--n-class 7 --n-class-offset 7 --model-name=model_7B_64\"\n","  main(\"7 class B\", option=option)\n","\n","  option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","           \"--lr 0.001 \" + \\\n","           \"--n-class 7 --n-class-offset 14 --model-name=model_7C_64\"\n","  main(\"7 class C\", option=option)\n","\n","  download_log()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_L2aWHOss4x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2f3d7127d56c475fbd501aa7781c009e","d854208b897146bea1e06186f290d14a","fd31ba0f2ef743c6bbae16f1a4025654","ac6bc450842a4bf683e8ab95341b00bf","cc82645be89a4dc8baf5dfef92d41f3c","75316bb5417f4f65a97628194116fc45","7b28c0b2a4934ab1873f0f395b1a5c51","c63ee816e50d4ad4a5637a42dd3186d6"]},"executionInfo":{"status":"error","timestamp":1592442938469,"user_tz":-540,"elapsed":1124768,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}},"outputId":"4295bb49-9023-4d90-ac4b-31115a8ff2d5"},"source":["if __name__ == '__main__':\n","  option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","           \"--lr 0.001 \" + \\\n","           \"--n-class 5 --n-class-offset 0 --model-name=model_5A_64\"\n","  main(\"5 class A\", option=option)\n","\n","  # option = \"--epochs 100 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","  #          \"--lr 0.001 \" + \\\n","  #          \"--n-class 5 --n-class-offset 5 --model-name=model_5B_64\"\n","  # main(\"5 class B\", option=option)\n","\n","  download_log()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[system] start\n","[meta] 5 class A\n","[param] batch_size=64\n","[param] epochs=100\n","[param] lr=0.001\n","[param] b1=0.9\n","[param] b2=0.999\n","[param] momentum=0.9\n","[param] dataset=cifar10\n","[param] n_class=5\n","[param] n_class_offset=0\n","[param] data_size=16000\n","[param] model=cnn\n","[param] optimizer=sdg\n","[param] criterion=cross_entropy_loss\n","[param] scheduler=\n","[param] t_max=10\n","[param] save_model=True\n","[param] model_name=model_5A_64\n","[device] cuda\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f3d7127d56c475fbd501aa7781c009e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","[0 1 2 3 4]\n"],"name":"stdout"},{"output_type":"stream","text":["[system] X\n","[system] epoch 0\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n","[test] ave loss : 1.6083,\taccu : 2313/9000(26%)\n","[system] epoch 1\n","[test] ave loss : 1.5973,\taccu : 2859/9000(32%)\n","[system] epoch 2\n","[test] ave loss : 1.5151,\taccu : 3133/9000(35%)\n","[system] epoch 3\n","[test] ave loss : 1.5379,\taccu : 2974/9000(33%)\n","[system] epoch 4\n","[test] ave loss : 1.4908,\taccu : 3490/9000(39%)\n","[system] epoch 5\n","[test] ave loss : 1.4832,\taccu : 3703/9000(41%)\n","[system] epoch 6\n","[test] ave loss : 1.4949,\taccu : 3556/9000(40%)\n","[system] epoch 7\n","[test] ave loss : 1.5059,\taccu : 3437/9000(38%)\n","[system] epoch 8\n","[test] ave loss : 1.4270,\taccu : 4233/9000(47%)\n","[system] epoch 9\n","[test] ave loss : 1.4147,\taccu : 4369/9000(49%)\n","[system] epoch 10\n","[test] ave loss : 1.3882,\taccu : 4590/9000(51%)\n","[system] epoch 11\n","[test] ave loss : 1.3838,\taccu : 4622/9000(51%)\n","[system] epoch 12\n","[test] ave loss : 1.3723,\taccu : 4736/9000(53%)\n","[system] epoch 13\n","[test] ave loss : 1.3506,\taccu : 4920/9000(55%)\n","[system] epoch 14\n","[test] ave loss : 1.3100,\taccu : 5266/9000(59%)\n","[system] epoch 15\n","[test] ave loss : 1.3110,\taccu : 5254/9000(58%)\n","[system] epoch 16\n","[test] ave loss : 1.3108,\taccu : 5281/9000(59%)\n","[system] epoch 17\n","[test] ave loss : 1.2141,\taccu : 6174/9000(69%)\n","[system] epoch 18\n","[test] ave loss : 1.2485,\taccu : 5851/9000(65%)\n","[system] epoch 19\n","[test] ave loss : 1.2138,\taccu : 6171/9000(69%)\n","[system] epoch 20\n","[test] ave loss : 1.1728,\taccu : 6553/9000(73%)\n","[system] epoch 21\n","[test] ave loss : 1.1716,\taccu : 6565/9000(73%)\n","[system] epoch 22\n","[test] ave loss : 1.1764,\taccu : 6526/9000(73%)\n","[system] epoch 23\n","[test] ave loss : 1.1423,\taccu : 6843/9000(76%)\n","[system] epoch 24\n","[test] ave loss : 1.1750,\taccu : 6553/9000(73%)\n","[system] epoch 25\n","[test] ave loss : 1.1296,\taccu : 6958/9000(77%)\n","[system] epoch 26\n","[test] ave loss : 1.1281,\taccu : 6957/9000(77%)\n","[system] epoch 27\n","[test] ave loss : 1.1245,\taccu : 6988/9000(78%)\n","[system] epoch 28\n","[test] ave loss : 1.1081,\taccu : 7146/9000(79%)\n","[system] epoch 29\n","[test] ave loss : 1.1377,\taccu : 6876/9000(76%)\n","[system] epoch 30\n","[test] ave loss : 1.1221,\taccu : 7018/9000(78%)\n","[system] epoch 31\n","[test] ave loss : 1.1090,\taccu : 7127/9000(79%)\n","[system] epoch 32\n","[test] ave loss : 1.1093,\taccu : 7133/9000(79%)\n","[system] epoch 33\n","[test] ave loss : 1.1272,\taccu : 6982/9000(78%)\n","[system] epoch 34\n","[test] ave loss : 1.1069,\taccu : 7159/9000(80%)\n","[system] epoch 35\n","[test] ave loss : 1.0890,\taccu : 7325/9000(81%)\n","[system] epoch 36\n","[test] ave loss : 1.0979,\taccu : 7248/9000(81%)\n","[system] epoch 37\n","[test] ave loss : 1.0965,\taccu : 7250/9000(81%)\n","[system] epoch 38\n","[test] ave loss : 1.0891,\taccu : 7329/9000(81%)\n","[system] epoch 39\n","[test] ave loss : 1.1039,\taccu : 7191/9000(80%)\n","[system] epoch 40\n","[test] ave loss : 1.0792,\taccu : 7409/9000(82%)\n","[system] epoch 41\n","[test] ave loss : 1.0959,\taccu : 7260/9000(81%)\n","[system] epoch 42\n","[test] ave loss : 1.0816,\taccu : 7392/9000(82%)\n","[system] epoch 43\n","[test] ave loss : 1.0710,\taccu : 7491/9000(83%)\n","[system] epoch 44\n","[test] ave loss : 1.0783,\taccu : 7419/9000(82%)\n","[system] epoch 45\n","[test] ave loss : 1.0811,\taccu : 7399/9000(82%)\n","[system] epoch 46\n","[test] ave loss : 1.0792,\taccu : 7410/9000(82%)\n","[system] epoch 47\n","[test] ave loss : 1.0609,\taccu : 7571/9000(84%)\n","[system] epoch 48\n","[test] ave loss : 1.0892,\taccu : 7330/9000(81%)\n","[system] epoch 49\n","[test] ave loss : 1.0585,\taccu : 7594/9000(84%)\n","[system] epoch 50\n","[test] ave loss : 1.0812,\taccu : 7407/9000(82%)\n","[system] epoch 51\n","[test] ave loss : 1.0646,\taccu : 7543/9000(84%)\n","[system] epoch 52\n","[test] ave loss : 1.0659,\taccu : 7534/9000(84%)\n","[system] epoch 53\n","[test] ave loss : 1.0974,\taccu : 7251/9000(81%)\n","[system] epoch 54\n","[test] ave loss : 1.0598,\taccu : 7589/9000(84%)\n","[system] epoch 55\n","[test] ave loss : 1.0727,\taccu : 7471/9000(83%)\n","[system] epoch 56\n","[test] ave loss : 1.0637,\taccu : 7560/9000(84%)\n","[system] epoch 57\n","[test] ave loss : 1.0550,\taccu : 7630/9000(85%)\n","[system] epoch 58\n","[test] ave loss : 1.0435,\taccu : 7728/9000(86%)\n","[system] epoch 59\n","[test] ave loss : 1.0600,\taccu : 7590/9000(84%)\n","[system] epoch 60\n","[test] ave loss : 1.0668,\taccu : 7537/9000(84%)\n","[system] epoch 61\n","[test] ave loss : 1.0715,\taccu : 7483/9000(83%)\n","[system] epoch 62\n","[test] ave loss : 1.0505,\taccu : 7682/9000(85%)\n","[system] epoch 63\n","[test] ave loss : 1.0457,\taccu : 7721/9000(86%)\n","[system] epoch 64\n","[test] ave loss : 1.0516,\taccu : 7654/9000(85%)\n","[system] epoch 65\n","[test] ave loss : 1.0737,\taccu : 7454/9000(83%)\n","[system] epoch 66\n","[test] ave loss : 1.0569,\taccu : 7611/9000(85%)\n","[system] epoch 67\n","[test] ave loss : 1.0544,\taccu : 7642/9000(85%)\n","[system] epoch 68\n","[test] ave loss : 1.0623,\taccu : 7578/9000(84%)\n","[system] epoch 69\n","[test] ave loss : 1.0527,\taccu : 7653/9000(85%)\n","[system] epoch 70\n","[test] ave loss : 1.0393,\taccu : 7778/9000(86%)\n","[system] epoch 71\n","[test] ave loss : 1.0363,\taccu : 7794/9000(87%)\n","[system] epoch 72\n","[test] ave loss : 1.0459,\taccu : 7710/9000(86%)\n","[system] epoch 73\n","[test] ave loss : 1.0520,\taccu : 7656/9000(85%)\n","[system] epoch 74\n","[test] ave loss : 1.0451,\taccu : 7728/9000(86%)\n","[system] epoch 75\n","[test] ave loss : 1.0423,\taccu : 7754/9000(86%)\n","[system] epoch 76\n","[test] ave loss : 1.0454,\taccu : 7722/9000(86%)\n","[system] epoch 77\n","[test] ave loss : 1.0419,\taccu : 7751/9000(86%)\n","[system] epoch 78\n","[test] ave loss : 1.0412,\taccu : 7761/9000(86%)\n","[system] epoch 79\n","[test] ave loss : 1.0374,\taccu : 7797/9000(87%)\n","[system] epoch 80\n","[test] ave loss : 1.0482,\taccu : 7698/9000(86%)\n","[system] epoch 81\n","[test] ave loss : 1.0431,\taccu : 7747/9000(86%)\n","[system] epoch 82\n","[test] ave loss : 1.0359,\taccu : 7812/9000(87%)\n","[system] epoch 83\n","[test] ave loss : 1.0306,\taccu : 7856/9000(87%)\n","[system] epoch 84\n","[test] ave loss : 1.0439,\taccu : 7736/9000(86%)\n","[system] epoch 85\n","[test] ave loss : 1.0476,\taccu : 7687/9000(85%)\n","[system] epoch 86\n","[test] ave loss : 1.0391,\taccu : 7774/9000(86%)\n","[system] epoch 87\n","[test] ave loss : 1.0367,\taccu : 7799/9000(87%)\n","[system] epoch 88\n","[test] ave loss : 1.0376,\taccu : 7792/9000(87%)\n","[system] epoch 89\n","[test] ave loss : 1.0382,\taccu : 7781/9000(86%)\n","[system] epoch 90\n","[test] ave loss : 1.0414,\taccu : 7755/9000(86%)\n","[system] epoch 91\n","[test] ave loss : 1.0433,\taccu : 7744/9000(86%)\n","[system] epoch 92\n","[test] ave loss : 1.0339,\taccu : 7826/9000(87%)\n","[system] epoch 93\n","[test] ave loss : 1.0380,\taccu : 7792/9000(87%)\n","[system] epoch 94\n","[test] ave loss : 1.0381,\taccu : 7791/9000(87%)\n","[system] epoch 95\n","[test] ave loss : 1.0388,\taccu : 7786/9000(87%)\n","[system] epoch 96\n","[test] ave loss : 1.0413,\taccu : 7759/9000(86%)\n","[system] epoch 97\n","[test] ave loss : 1.0359,\taccu : 7805/9000(87%)\n","[system] epoch 98\n","[test] ave loss : 1.0470,\taccu : 7718/9000(86%)\n","[system] epoch 99\n","[test] ave loss : 1.0386,\taccu : 7785/9000(86%)\n","[system] saving...\n","[stat] X train loss : [2.2051901817321777, 2.182957410812378, 2.133073091506958, 2.1030852794647217, 2.0752620697021484, 1.9960905313491821, 1.943868637084961, 1.885083794593811, 1.811237096786499, 1.8541316986083984, 1.8291224241256714, 1.7937300205230713, 1.7996177673339844, 1.775675654411316, 1.8087798357009888, 1.7080788612365723, 1.6461496353149414, 1.6745437383651733, 1.6623212099075317, 1.7291958332061768, 1.6468558311462402, 1.750542163848877, 1.678797960281372, 1.6664613485336304, 1.638590693473816, 1.6853318214416504, 1.6132605075836182, 1.6319119930267334, 1.6525274515151978, 1.5989978313446045, 1.648324728012085, 1.5890300273895264, 1.5900381803512573, 1.5837533473968506, 1.5722017288208008, 1.5523192882537842, 1.5594502687454224, 1.563858151435852, 1.554284691810608, 1.5348162651062012, 1.5247822999954224, 1.5659105777740479, 1.4992910623550415, 1.5410174131393433, 1.4972963333129883, 1.5188910961151123, 1.5255813598632812, 1.528398036956787, 1.5110855102539062, 1.5293972492218018, 1.5370227098464966, 1.5242317914962769, 1.520475149154663, 1.544283151626587, 1.5479037761688232, 1.5201836824417114, 1.506455659866333, 1.5212318897247314, 1.5022304058074951, 1.4923925399780273, 1.5149199962615967, 1.532008409500122, 1.5017038583755493, 1.4989124536514282, 1.5063227415084839, 1.5087531805038452, 1.5065195560455322, 1.5025622844696045, 1.4929602146148682, 1.4903600215911865, 1.461830496788025, 1.4907547235488892, 1.4819289445877075, 1.502026081085205, 1.4990686178207397, 1.4862009286880493, 1.4767757654190063, 1.4834691286087036, 1.5081791877746582, 1.4895873069763184, 1.4673726558685303, 1.4727270603179932, 1.4811344146728516, 1.4910396337509155, 1.4620774984359741, 1.4742344617843628, 1.461552381515503, 1.5002832412719727, 1.5034157037734985, 1.4622204303741455, 1.4872195720672607, 1.478878140449524, 1.4711252450942993, 1.5087554454803467, 1.4785171747207642, 1.461193323135376, 1.4619051218032837, 1.476191520690918, 1.4880262613296509, 1.4612404108047485]\n","[stat] X test loss : [1.6082991835073377, 1.5973179179725918, 1.5151414101850902, 1.5379246524039736, 1.490829402673329, 1.4831758746018646, 1.4948923697708347, 1.5058668564397393, 1.4269625405047803, 1.4147153255787301, 1.3881665476670502, 1.3837873183243663, 1.3723426651447377, 1.3505522714439013, 1.3100291228463463, 1.3110399026397273, 1.310828726342384, 1.2141338468443417, 1.248522497237997, 1.2137681025985285, 1.1728130257721487, 1.171637198603745, 1.1764398305974109, 1.1422688567892034, 1.1749512396805675, 1.1295553023088063, 1.1280857595146125, 1.1245428611200752, 1.1081290439511022, 1.1377347293474995, 1.122064007934949, 1.1089600155539547, 1.1092766223224342, 1.127241056016151, 1.1069411757989978, 1.0889922380447388, 1.0979283058896978, 1.096480961387039, 1.0890610023593226, 1.1038982838603622, 1.0792356175733797, 1.095908152296188, 1.0816100607527064, 1.0710278330965246, 1.0782766371754045, 1.081129215287824, 1.079234373484943, 1.0609015243273254, 1.0892199632969308, 1.058537024132749, 1.0812249513382608, 1.0645818997782173, 1.0658684402492875, 1.097361460645148, 1.0597960948944092, 1.0727207043492202, 1.063702105207646, 1.0549639632515873, 1.0434673280580669, 1.059950223205783, 1.066784404271038, 1.0715493991019878, 1.0504671808675672, 1.0456685669033239, 1.0516105171636487, 1.0736593735133502, 1.0569149991299243, 1.05438853493819, 1.0623167178309556, 1.052728756945184, 1.0393307851561417, 1.0363334003069722, 1.0459277397351907, 1.0519854341838377, 1.0450702102471752, 1.0423188822489258, 1.0453698165873264, 1.0418864273010415, 1.0412270528204897, 1.0374491654389293, 1.0482000230897404, 1.043083961973799, 1.035863364841921, 1.030600740131757, 1.0438722680646477, 1.0476076898845375, 1.0391211370204358, 1.0367499192555745, 1.037592834191965, 1.038197266294601, 1.0413620915818722, 1.0433397766546155, 1.0339310253765566, 1.038045993510713, 1.0380932337848852, 1.038796716125299, 1.0413048043318673, 1.035941183144319, 1.0470499083505456, 1.0385999358292166]\n","[stat] X accuracy : [25.7, 31.766666666666666, 34.81111111111111, 33.044444444444444, 38.77777777777778, 41.144444444444446, 39.51111111111111, 38.18888888888889, 47.03333333333333, 48.544444444444444, 51.0, 51.355555555555554, 52.62222222222222, 54.666666666666664, 58.51111111111111, 58.37777777777778, 58.67777777777778, 68.6, 65.0111111111111, 68.56666666666666, 72.81111111111112, 72.94444444444444, 72.5111111111111, 76.03333333333333, 72.81111111111112, 77.31111111111112, 77.3, 77.64444444444445, 79.4, 76.4, 77.97777777777777, 79.18888888888888, 79.25555555555556, 77.57777777777778, 79.54444444444445, 81.38888888888889, 80.53333333333333, 80.55555555555556, 81.43333333333334, 79.9, 82.32222222222222, 80.66666666666667, 82.13333333333334, 83.23333333333333, 82.43333333333334, 82.21111111111111, 82.33333333333333, 84.12222222222222, 81.44444444444444, 84.37777777777778, 82.3, 83.81111111111112, 83.71111111111111, 80.56666666666666, 84.32222222222222, 83.0111111111111, 84.0, 84.77777777777777, 85.86666666666666, 84.33333333333333, 83.74444444444444, 83.14444444444445, 85.35555555555555, 85.78888888888889, 85.04444444444445, 82.82222222222222, 84.56666666666666, 84.91111111111111, 84.2, 85.03333333333333, 86.42222222222222, 86.6, 85.66666666666667, 85.06666666666666, 85.86666666666666, 86.15555555555555, 85.8, 86.12222222222222, 86.23333333333333, 86.63333333333334, 85.53333333333333, 86.07777777777778, 86.8, 87.28888888888889, 85.95555555555555, 85.41111111111111, 86.37777777777778, 86.65555555555555, 86.57777777777778, 86.45555555555555, 86.16666666666667, 86.04444444444445, 86.95555555555555, 86.57777777777778, 86.56666666666666, 86.5111111111111, 86.21111111111111, 86.72222222222223, 85.75555555555556, 86.5]\n","[stat] elapsed time : 1118.9469752311707[s]\n","[system] finish\n"],"name":"stderr"},{"output_type":"stream","text":["/content/log.txt\n"],"name":"stdout"},{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e66587c6cb70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# main(\"5 class B\", option=option)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mdownload_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-180865867cac>\u001b[0m in \u001b[0;36mdownload_log\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mresult_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"log.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    185\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m   })\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"]}]},{"cell_type":"code","metadata":{"id":"-Nqk3qVlRk3W","colab_type":"code","colab":{}},"source":["if __name__ == '__main__':\n","  # option = \"--epochs 100 --batch-size 128 --optimizer sdg --data-size 4000 \" + \\\n","  #          \"--lr 0.01 \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\"\n","  # main(\"7 class debug\", option=option) # 65%\n","\n","  # option = \"--epochs 300 --batch-size 512 --optimizer sdg --data-size 2000 \" + \\\n","  #          \"--lr 0.1 --scheduler step \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\" # 52%\n","  # main(\"7 class debug\", option=option)\n","\n","  # option = \"--epochs 100 --batch-size 32 --optimizer sdg --data-size 8000 \" + \\\n","  #          \"--lr 0.001 \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\" # 75%, 30min\n","  # main(\"7 class debug\", option=option)\n","  \n","  # option = \"--epochs 150 --batch-size 64 --optimizer sdg --data-size 16000 \" + \\\n","  #          \"--lr 0.001 \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\" # 80%, 50min\n","  # main(\"7 class debug\", option=option)\n","\n","  # option = \"--epochs 150 --batch-size 16 --optimizer sdg --data-size 4000 \" + \\\n","  #          \"--lr 0.001 \" + \\\n","  #          \"--n-class 7 --n-class-offset 0 --model-name=model\" # 68%, 30min\n","  # main(\"7 class debug\", option=option)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPNsrhFWH2C5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592441802860,"user_tz":-540,"elapsed":830,"user":{"displayName":"Yy Yy","photoUrl":"","userId":"02437050620110452344"}}},"source":["def download_log():\n","  result_path = \"log.txt\"\n","  print(os.path.join(\"/content\", result_path))\n","  files.download(os.path.join(\"/content\", result_path))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"PV5pwc4qH3ab","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}